{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from my_library.library import *\n",
    "from hyperopt import hp, tpe, Trials, fmin,STATUS_OK\n",
    "from my_library.funcs import *\n",
    "from scipy import fftpack\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# path win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tpx = '/Users/Owner/Desktop/StockPriceData/Stock_index/TOPIX_10years.csv'\n",
    "path_225 = '/Users/Owner/Desktop/StockPriceData/Stock_index/NK225_10years.csv'\n",
    "path_daw = '/Users/Owner/Desktop/StockPriceData/Stock_index/DAW_10years.csv'\n",
    "path_bear = '/Users/Owner/Desktop/StockPriceData/Stock_index/R225BEAR_10years.csv'\n",
    "path_tpx_sim = '/Users/Owner/Desktop/StockPriceData/TOPIX/TOPIX_20211208.csv'\n",
    "path_daw_sim = '/Users/Owner/Desktop/StockPriceData/DAW/DAW_20211208.csv'\n",
    "save_pickle_path = '/Users/Owner/Desktop/program/Sotsuron/code/wave_pickles'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gyosyu_df(path_gyosyu = '/Users/Owner/Desktop/StockPriceData/Gyosyu/'):\n",
    "    FILE = glob.glob(path_gyosyu+'*.csv')\n",
    "    df_dict = {}\n",
    "    for file in FILE:\n",
    "        name = file.replace(path_gyosyu,'')[:-4]\n",
    "        df = pd.read_csv(file)\n",
    "        df = df.rename(columns={df.columns[0]:'nan',df.columns[1]:'nan',df.columns[2]:'nan',\\\n",
    "                                    df.columns[3]:'day',df.columns[4]:'nan',df.columns[5]:'open',\\\n",
    "                                    df.columns[6]:'high',df.columns[7]:'low',df.columns[8]:'close',\\\n",
    "                                        df.columns[9]:'volume',})\n",
    "        df = df.drop('nan',axis=1)\n",
    "        df = df.drop(df.index[0])\n",
    "        df['day'] = pd.to_datetime(df['day'],format='%Y/%m/%d')\n",
    "        df.set_index('day',inplace=True)\n",
    "        df_dict[name] = df\n",
    "\n",
    "    return df_dict,FILE\n",
    "\n",
    "def return_corr(df):\n",
    "    x = df['daw_close'].values\n",
    "    y = df['close'].values\n",
    "    corr = np.corrcoef(x,y)\n",
    "    return corr\n",
    "\n",
    "def split_df(df,start_year,end_year,start_month=1,end_month=12):\n",
    "    df = df[df.index.year<=end_year]\n",
    "    df = df[df.index.year>=start_year]\n",
    "    df = df[df.index.month<=end_month]\n",
    "    if start_month>0:\n",
    "        df = df[df.index.month>=start_month]\n",
    "    return df\n",
    "\n",
    "def make_value_list(lx,start_year,end_year,path_tpx,path_daw,alpha=0.34,width=20,stride=10,start_month=1,end_month=12):\n",
    "\n",
    "    lc_dummy = LearnClustering(width=width)\n",
    "    df_con = lc_dummy.make_df_con(path_tpx,path_daw)\n",
    "    \n",
    "    df_con = split_df(df_con,start_year,end_year,start_month,end_month)\n",
    "    \n",
    "    x_,z_ = lc_dummy.make_x_data(df_con['close'],stride=stride,test_rate=1.0,width=width)\n",
    "    length = len(z_)\n",
    "    value_list = []\n",
    "\n",
    "    for i in range(length):\n",
    "        for strategy in ['normal','reverse']:\n",
    "            try:\n",
    "                # 本当はXGBSimulation2\n",
    "                xl = XGBSimulation2(lx,alpha=alpha)\n",
    "                xl.simulate(path_tpx,path_daw,strategy=strategy,is_validate=True,start_year=start_year,end_year=end_year,df_=z_[i])\n",
    "                \n",
    "                trade_log =  xl.trade_log\n",
    "                total_profit = trade_log['total_profit'].values[0]\n",
    "                stock_wave = z_[i]\n",
    "                vt = ValueTable(strategy,alpha,total_profit,trade_log,stock_wave)\n",
    "                value_list.append(vt)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "    return value_list\n",
    "\n",
    "def return_clx(Value_list):\n",
    "    Value_good = sorted(Value_list,key=lambda x :x[2],reverse=True)\n",
    "    Value_bad = sorted(Value_list,key=lambda x :x[2],reverse=False)\n",
    "    ng = []\n",
    "    rg = []\n",
    "    nb = []\n",
    "    rb = []\n",
    "    \n",
    "    # 1sigam = 外れ値 として処理する\n",
    "    prf_list=[]\n",
    "    for vg in Value_good:\n",
    "        total_profit = vg.total_profit\n",
    "        prf_list.append(total_profit)      \n",
    "    prf_array = np.array(prf_list)\n",
    "    st_prf = standarize(prf_array)\n",
    "\n",
    "    for idx,v in enumerate(Value_good):\n",
    "        if v.total_profit<=0:break\n",
    "        # if np.abs(st_prf[idx]) >=1:continue    \n",
    "\n",
    "        df = v.stock_wave\n",
    "        strategy = v.strategy\n",
    "        # print(df)\n",
    "        # break\n",
    "        if strategy==\"normal\":\n",
    "            ng.append(standarize(df))\n",
    "        else:\n",
    "            rg.append(standarize(df))\n",
    "\n",
    "    prf_list=[]\n",
    "    for vb in Value_bad:\n",
    "        total_profit = vb.total_profit\n",
    "        prf_list.append(total_profit)      \n",
    "    prf_array = np.array(prf_list)\n",
    "    st_prf = standarize(prf_array)\n",
    "\n",
    "    for v in Value_bad:\n",
    "        if v.total_profit>=0 :break\n",
    "        # if np.abs(st_prf[idx]) >=1:continue  \n",
    "        \n",
    "        df = v.stock_wave\n",
    "        strategy = v.strategy\n",
    "\n",
    "        if strategy==\"normal\":\n",
    "            nb.append(standarize(df))\n",
    "        else:\n",
    "            rb.append(standarize(df))\n",
    "\n",
    "    x_ng = make_easy_x(ng)\n",
    "    x_nb = make_easy_x(nb)\n",
    "    x_rg = make_easy_x(rg)\n",
    "    x_rb = make_easy_x(rb)\n",
    "    return x_ng,x_nb,x_rg,x_rb\n",
    "\n",
    "def return_ffs(lx,x_ng,x_nb,x_rg,x_rb,FFT_simulation,width=20,stride=10,window_type='none',is_high_pass=False,is_low_pass=True,cut_off=3):\n",
    "\n",
    "\n",
    "    log_dict = {}\n",
    "    cs_dict = {}\n",
    "    ffs_dict = {}\n",
    "    \n",
    "\n",
    "    random_state=0\n",
    "\n",
    "    alpha = 0.33\n",
    "    n_cluster = 1\n",
    "        \n",
    "    Fstrategies = []\n",
    "    Wstrategies = []\n",
    "    Cstrategies = []\n",
    "    F_list = []\n",
    "    Phases = []\n",
    "    lc_rg = LearnClustering(n_cluster=n_cluster,random_state=random_state)\n",
    "    lc_rg.learn_clustering3(x_rg,width=width)\n",
    "    lc_rb = LearnClustering(n_cluster=n_cluster,random_state=random_state)\n",
    "    lc_rb.learn_clustering3(x_rb,width=width)\n",
    "    lc_ng = LearnClustering(n_cluster=n_cluster,random_state=random_state)\n",
    "    lc_ng.learn_clustering3(x_ng,width=width)\n",
    "    lc_nb = LearnClustering(n_cluster=n_cluster,random_state=random_state)\n",
    "    lc_nb.learn_clustering3(x_nb,width=width)\n",
    "\n",
    "    strategy_list = ['normal','stay','reverse','stay']\n",
    "\n",
    "    j=0\n",
    "    fft_dummy = FFTSimulation(lx,None,width=width,window_type=window_type,is_low_pass=is_low_pass,is_high_pass=is_high_pass,cut_off=cut_off)\n",
    "    for lc in [lc_ng,lc_nb,lc_rg,lc_rb]:\n",
    "        \n",
    "        for _,key in enumerate(lc.wave_dict):\n",
    "            wave = lc.wave_dict[key]\n",
    "            # このタイミングでハイパスフィルタかける\n",
    "            # make_spectrum 内の関数をいじる\n",
    "            spe = fft_dummy.make_spectrum(wave)\n",
    "            ceps = fft_dummy.make_cepstrum(spe)\n",
    "            F,Amp = fft_dummy.do_fft(wave)\n",
    "            F = F[:len(F)//2]\n",
    "            phase = np.degrees(np.angle(F))\n",
    "            strategy = strategy_list[j]\n",
    "            fs  = Fstrategy(strategy,alpha,spe)\n",
    "            ws = Fstrategy(strategy,alpha,wave)\n",
    "            ph = Fstrategy(strategy,alpha,phase)\n",
    "            cs = Fstrategy(strategy,alpha,ceps)\n",
    "            \n",
    "            Fstrategies.append(fs)\n",
    "            Wstrategies.append(ws)\n",
    "            Cstrategies.append(cs)\n",
    "            Phases.append(ph)\n",
    "            F_list.append(F)\n",
    "        j+=1\n",
    "\n",
    "    return Fstrategies,Phases,F_list,Cstrategies\n",
    "\n",
    "def return_fft_list(lx,x_,FFT_obj,width=20):\n",
    "\n",
    "    fft_list = []\n",
    "    fft_dummy = FFT_obj(lx,None,width=width)\n",
    "    for wave in x_:\n",
    "        spe = fft_dummy.make_spectrum(wave)\n",
    "        fft_list.append(spe)\n",
    "        \n",
    "    return fft_list        \n",
    "\n",
    "def return_cumulative_fst(Fstrategies_new,Fstrategies_old):\n",
    "    Fstrategies = []\n",
    "    strategy_list = ['normal','stay','reverse','stay']\n",
    "\n",
    "    for idx,fst in enumerate(Fstrategies_new):\n",
    "        spe_new = fst.spectrum\n",
    "        fst_old = Fstrategies_old[idx]\n",
    "        spe_old = fst_old.spectrum\n",
    "        spe_new = standarize(spe_new+spe_old)\n",
    "\n",
    "        \n",
    "        fs  = Fstrategy(fst_old.strategy,0.33,spe_new)\n",
    "        Fstrategies.append(fs)\n",
    "    \n",
    "    return Fstrategies\n",
    "\n",
    "def concat_list(key_list,value_dict):\n",
    "    value_list = []\n",
    "    for key in key_list:\n",
    "        v_lis = value_dict[key]\n",
    "        for v in v_lis:\n",
    "            value_list.append(v)\n",
    "    return value_list\n",
    "\n",
    "def return_ffs_dict(value_dict,lx_dict,width=40,stride=5,window_type='bla',is_high_pass=False,is_low_pass=True,is_ceps=False,cut_off=3):\n",
    "    ffs_dict = {}\n",
    "    trade_dict = {}\n",
    "    lx_dummy = LearnXGB(num_class=3)\n",
    "    x_train,y_train,_,_= lx_dummy.make_xgb_data(path_tpx,path_daw,test_rate=1.0)\n",
    "    _,_ ,x_test,y_test = lx_dummy.make_xgb_data(path_tpx,path_daw,test_rate=0.9)\n",
    "    F_list = []\n",
    "    F_lis_dict = {}\n",
    "    limit_year = 2009\n",
    "\n",
    "    for year in range(limit_year+2,2022):\n",
    "        print(year)\n",
    "\n",
    "        start_month=1\n",
    "        end_month = 12\n",
    "        start_year = year\n",
    "        end_year = year\n",
    "        value_list = value_dict[str(year-1)]\n",
    "        lx_ = lx_dict[str(year-1)]\n",
    "\n",
    "        x_ng,x_nb,x_rg,x_rb = return_clx(value_list)\n",
    "\n",
    "        try:\n",
    "            Fstrategies,_,F_list,Cstrategies = return_ffs(lx_,x_ng,x_nb,x_rg,x_rb,FFTSimulation,width=width,stride=stride,\\\n",
    "                window_type=window_type,is_high_pass=is_high_pass,is_low_pass=is_low_pass,cut_off=cut_off)\n",
    "            \"\"\"\n",
    "            # Fstrategies をどんどん加算していく    \n",
    "            # if len(ffs_dict)>0:\n",
    "            #     last_key = next(reversed(ffs_dict),None)\n",
    "            #     Fstrategies_old = ffs_dict[last_key].Fstrategies\n",
    "            #     Fstrategies = return_cumulative_fst(Fstrategies,Fstrategies_old)\n",
    "            \"\"\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            last_key = next(reversed(ffs_dict),None)\n",
    "            Fstrategies = ffs_dict[last_key].Fstrategies\n",
    "            # Cepstrum で　やってみる\n",
    "            # Cstrategies = ffs_dict[last_key].Fstrategies\n",
    "            \n",
    "        \n",
    "        # ffs = FFTSimulation(lx,Fstrategies,width=width,window_type=window_type)\n",
    "        ffs = FFTSimulation(lx_,Fstrategies,width=width,window_type=window_type,is_ceps=is_ceps,\\\n",
    "            is_high_pass=is_high_pass,is_low_pass=is_low_pass,cut_off=cut_off)\n",
    "        ffs.simulate(path_tpx,path_daw,start_year=year,end_year=year,is_validate=True)\n",
    "        \n",
    "        ffs_dict[str(year)] = ffs\n",
    "        trade_dict[str(year)] = ffs.trade_log\n",
    "        F_lis_dict[str(year)] = F_list\n",
    "    \n",
    "    return ffs_dict, trade_dict, F_lis_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_dict = load_pickle(save_pickle_path+'/value_dict.pickle')\n",
    "lx_dict = load_pickle(save_pickle_path+'/lx_dict.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "save_path = '/Users/Owner/Desktop/program/Sotsuron/code/wave_pickles/value_dict.pickle'\n",
    "save_pickle(save_path,value_dict)\n",
    "\n",
    "save_path = '/Users/Owner/Desktop/program/Sotsuron/code/wave_pickles/lx_dict.pickle'\n",
    "save_pickle(save_path,lx_dict)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 周波数成分プロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "for idx,key in enumerate(ffs_dict):\n",
    "    Fstrategies = ffs_dict[key].Fstrategies\n",
    "    # 0 : ng, 1 : nb, 2 : rg, 3: rb\n",
    "    print(key)\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), facecolor=\"w\")\n",
    "    \n",
    "    for idx,fs in enumerate(Fstrategies):\n",
    "        if idx==0:\n",
    "            label='ng'\n",
    "        elif idx == 1:\n",
    "            label='nb'\n",
    "        elif idx == 2:\n",
    "            label='rg'\n",
    "        elif idx == 3:\n",
    "            label='rb'\n",
    "        ax.plot(fs.spectrum,label=label,marker='o',markersize=7)\n",
    "    \n",
    "\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 収益確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_profit = 0\n",
    "mean_profit = 0\n",
    "mean_profit_rate = 0\n",
    "total_profit_rate = 0\n",
    "for idx,key in enumerate(trade_dict):\n",
    "    print(key)\n",
    "    print(trade_dict[key])\n",
    "    td = trade_dict[key]\n",
    "    total_profit += td['total_profit'].values[0]\n",
    "    total_profit_rate += td['profit rate'].values[0]\n",
    "    \n",
    "mean_profit = total_profit/(idx+1)\n",
    "mean_profit_rate = (total_profit_rate)/(idx+1)\n",
    "\n",
    "print('total profit :{0}'.format(total_profit))\n",
    "print('mean profit :{0}'.format(mean_profit))\n",
    "print('total profit rate :{0}'.format(total_profit_rate))\n",
    "print('mean profit rate : {0}'.format(mean_profit_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low pass vs High pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6ca01a9d29b8f49b2398e47ff0a4f0d82a4b97eff954d8fa800ff949016a671"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
